{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão de odds e de resultados exatos\n",
    "\n",
    "### Introdução\n",
    "\n",
    "O objetivo deste projeto é efetuar a previsão de resultados exatos e das odds associadas de forma precisa tendo por base o dataset fornececido.\n",
    "\n",
    "Este dataset tem informações básicas sobre o jogo (quais os jogadores em campo, as suas posições, número de golos, cartões, posse de bola, entre outros), estatísticas da FIFA acerca dos jogadores e dados de odds provenientes de diversas casas de apostas (nomeadamente BET365, ... , ...) . \n",
    "\n",
    "Foi construído um modelo que permite prever o resultado exato de um jogo, isto é o número de golos da equipa da casa e da equipa de fora. Através de um segundo modelo desenvolvido, é ainda possível prever as odds para os três cenários possíveis de um determinado jogo - vitória da equipa da casa, empate ou vitória da equipa de fora.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import sqlite3\n",
    "from sklearn import preprocessing\n",
    "import missingno as msno\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"./database.sqlite\")\n",
    "display_graph = False\n",
    "\n",
    "def clean_data(data):\n",
    "    #this line displays the NaN distribution before data clean up\n",
    "    if display_graph:\n",
    "        msno.matrix(data)\n",
    "    data = data.replace(\"\", np.NaN)\n",
    "    data = data.dropna()\n",
    "    if display_graph:\n",
    "        msno.matrix(data)\n",
    "    return data\n",
    "\n",
    "def preprocess_data() :\n",
    "    matches = pd.read_sql_query('SELECT *, strftime(\"%Y\",date) as year, (B365H + BWH + IWH + LBH + WHH +  VCH )/6 AS home_odds, (B365D + BWD + IWD + LBD + WHD + VCD)/6 AS draw_odds,  (B365A + BWA + IWA + LBA + WHA + VCA )/6 AS away_odds FROM match',con)\n",
    "    matches = matches.iloc[:, np.r_[0,2,4,7,8,9,10, 55:77, 115:119 ]]\n",
    "\n",
    "    teams = pd.read_sql_query('SELECT team_api_id, (buildUpPlaySpeed + buildUpPlayDribbling + buildUpPlayPassing + defencePressure + defenceAggression + defenceTeamWidth)/6 as team_rating FROM team_attributes', con)\n",
    "    players = pd.read_sql_query('SELECT player_api_id, strftime(\"%Y\",date) as year, avg(potential) as player_potential, avg(overall_rating) as rating FROM player_attributes GROUP BY player_api_id, year', con)\n",
    "    \n",
    "    matches = clean_data(matches)\n",
    "    teams = clean_data(teams)\n",
    "    players = clean_data(players)\n",
    "      \n",
    "    result =pd.merge(matches, teams, left_on='home_team_api_id', right_on='team_api_id', how='left').drop('team_api_id', axis=1)\n",
    "    result =pd.merge(result, teams, left_on='away_team_api_id', right_on='team_api_id', how='left').drop('team_api_id', axis=1)\n",
    "    result.rename(columns={\"team_rating_x\": \"home_team_rating\", \"team_rating_y\": \"away_team_rating\"}, inplace=True)\n",
    "\n",
    "    for index in range(1,12):\n",
    "        player_home_id = \"home_player_\" + str(index)\n",
    "        player_away_id = \"away_player_\" + str(index)\n",
    "        result =pd.merge(result, players, left_on=[player_home_id, 'year'], right_on=['player_api_id', 'year'], how='left').drop('player_api_id', axis=1)\n",
    "        result =pd.merge(result, players, left_on=[player_away_id, 'year'], right_on=['player_api_id', 'year'], how='left').drop('player_api_id', axis=1)\n",
    "        result.rename(columns={\"player_potential_x\": player_home_id + \"_potential\", \"player_potential_y\": player_away_id + \"_potential\" , \"rating_x\": player_home_id + \"_rating\", \"rating_y\": player_away_id + \"_rating\"}, inplace=True)\n",
    "    \n",
    "    #matches = preprocessing.scale(matches)\n",
    "    result = clean_data(result)\n",
    "    #display(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X_train, Y_train, X_test, Y_test):\n",
    "    reg = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "    #print(r2_score(Y_test, y_pred))\n",
    "\n",
    "    \n",
    "    #plt.scatter(X_test, Y_test,  color='gray')\n",
    "    #plt.plot(X_test, y_pred, color='red', linewidth=2)\n",
    "    #plt.show()\n",
    "    #print(reg.intercept_)\n",
    "\n",
    "\n",
    "    #print(reg.coef_)\n",
    "    \n",
    "    #reg.intercept_\n",
    "\n",
    "  #  reg.predict(np.array([[3, 5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_call(X): \n",
    "    pca = PCA()\n",
    "    pca.fit(X)\n",
    "    \n",
    "    print(pca.explained_variance_ratio_)\n",
    "    print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def calculate_odds(match_id):\n",
    "#match = pd.read_sql_query('SELECT * FROM match WHERE id = {}'.format(1), con)\n",
    "dataset = preprocess_data()\n",
    "X = dataset.iloc[:, np.r_[0:30, 33:79]]\n",
    "X = preprocessing.scale(X)\n",
    "Y = dataset.iloc[:, 30:33]\n",
    "Y = preprocessing.scale(Y)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size= 0.3)\n",
    "\n",
    "linear_regression(X_train, Y_train, X_test, Y_test)\n",
    "PCA_call(X)\n",
    "\n",
    "def get_team_info(team_id, year):\n",
    "    team_quality = pd.read_sql_query('SELECT (buildUpPlaySpeed + buildUpPlayDribbling + buildUpPlayPassing + defencePressure + defenceAggression + defenceTeamWidth)/6 as AVG FROM team_attributes WHERE team_api_id = {} AND date LIKE \"{}%\"'.format(team_id, year), con)\n",
    "    return team_quality #for now\n",
    "#home_team_data = get_team_info(match.home_team_api_id, match.date)\n",
    "#away_team_data = get_team_info(match.away_team_api_id, match.date)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Tema 4C, 27/05/2020\n",
    "\n",
    "* João Alberto Preto Rodrigues Praça, up201704748@fe.up.pt \n",
    "* Liliana Natacha Nogueira de Almeida, up201706908@fe.up.pt\t\n",
    "* Silvia Jorge Moreira da Rocha, up201704684@fe.up.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
