{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão de Odds em Jogos de Futebol Europeu\n",
    "\n",
    "***\n",
    "Tema 4C, 27/05/2020\n",
    "\n",
    "* João Alberto Preto Rodrigues Praça, up201704748@fe.up.pt \n",
    "* Liliana Natacha Nogueira de Almeida, up201706908@fe.up.pt\t\n",
    "* Silvia Jorge Moreira da Rocha, up201704684@fe.up.pt\n",
    "\n",
    "Faculdade de Engenharia da Universidade do Porto <br/>\n",
    "Mestrado Integrado em Engenharia Informática e Computação, Inteligência Artificial\n",
    "\n",
    "\n",
    "#### Resumo\n",
    "\n",
    "Neste artigo são abordados diferentes métodos de aprendizagem computacional, mais especificamente de aprendizagem supervisionada, na resolução de problemas de regressão. O problema em particular abordado é o de cálculo de odds para jogos, de futebol europeu, tendo por base o dataset fornecido. Existe uma fase inicial de pré-processamento dos dados (que engloba a limpeza e exploração dos dataset fornecido), seguida pela aplicação dos seguintes algoritmos: K-nearest neighbour, decision trees, neural networks e support vector machines.\n",
    "....................................................(resultados e conclusões)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introdução\n",
    "\n",
    "O objetivo deste projeto é resolver um problema de regressão, nomeadamente a previsão de odds em jogos de futebol europeu, através da aplicação de diferentes métodos de Machine Learning, mais especificamente de aprendizagem supervisionada. \n",
    "\n",
    "Machine Learning é uma área da inteligência artificial que permite a um sistema computacional aprender através do reconhecimento de padrões, melhorando progressivamente a performance numa tarefa específica, sem ser programada especificamente para o efeito. \n",
    "\n",
    "Neste artigo iremos focar-nos na aprendizagem supervisionada que se baseia no mapeamento de inputs em outputs através do treino de um modelo. Deste modo, são fornecidos dados ao sistema, juntamente com o output desejado, de forma a ensiná-lo e ajudá-lo na identificação de padrões. Esta fase de treino irá permitir a criação de um modelo capaz de prever outputs para novos inputs daquele tipo.\n",
    "\n",
    "O problema abordado neste documento é de regressão dado que a variável a prever (odds) é um valor real.\n",
    "\n",
    "As odds de um jogo de futebol são cotações dadas a um determinado jogo, ou seja, definem a probabilidade de um determinado evento ocorrer. Tipicamente, as odds são calculadas por especialistas e são previstas tendo por base diversos dados estatísticos como: informações sobre a equipa, dados sobre os jogos ou eventos.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Descrição do problema e dataset\n",
    "\n",
    "Este dataset tem informações básicas sobre o jogo (qual o país, época, liga, jornada, data, os jogadores em campo, as suas posições, número de golos), estatísticas da FIFA acerca dos jogadores (um rating geral, o potencial, altura, peso, entre outros) e das equipas (build-up através de passes, build-up através de dribles, pressão defensiva, pressão ofensiva, criação de passes e remates, entre outros ) e dados de odds provenientes de diversas casas de apostas.\n",
    "\n",
    "O problema de regressão em causa consiste na previsão de odds para os três cenários possíveis de um determinado jogo - vitória da equipa da casa, empate ou vitória da equipa de fora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Approach \n",
    "\n",
    "Tendo em conta a constituição do dataset, já descrita anteriormente, foram seguidos os seguintes passos na fase de seleção de dados:\n",
    "\n",
    "* Na tabela relativa aos atributos de uma dada equipa, decidimos compilar todos os dados fornecidos através da média ponderada dos valores de build-up através de velocidade, build-up através de drible, build-up através de passes, pressão defensiva, pressão ofensiva e largura da defesa. \n",
    "* Na tabela relativa aos atributos de um jogador não foram utilizados nenhuns dados uma vez que o dataset é composto por informação proveniente da FIFA e, portanto, a pontuação da equipa num dado momento é uma média ponderada dos seus jogadores. Deste modo, a utilização destes dados iria acrescentar complexidade e redundância sem melhorar os resultados obtidos.\n",
    "* Na tabela relativa aos jogos, foram utilizados os golos da equipa da casa, da equipa de fora e uma média ponderada das odds das casas de apostas. Nesta média, foram excluídas algumas casas que apresentavam uma elevada percentagem de dados com valores omissos.\n",
    "* As restantes tabelas foram apenas utilizadas para unir estas informações dado que não apresentavam mais nenhum dado relevante.\n",
    "\n",
    "De seguida, efetuámos o pré-processamento destes dados. Nesta fase, os dados omissos foram uniformizados e, de seguida, foram removidas todas as linhas que os incluíam. A opção de eliminar linhas com dados omissos ao invés de os substituir por outros valores (como por exemplo a média de valores da coluna) assenta em dois motivos: a elevada dimensão do dataset permite que a perda de alguns dados não se demonstre relevante e a aplicação de operações usando todos os dados válidos de uma coluna (como por exemplo a de odds) não permitiria a obtenção de um valor próximo daquele que seria o valor real, uma vez que para cada jogo as equipas participantes são diferentes e portanto os dados dessa coluna não têm relação entre si.\n",
    "\n",
    "Após isto, surge a fase de transformação. Nesta fase foi aplicada a normalização sobre os valores das variáveis a serem utilizadas pelos algoritmos de cálculo de regressão.\n",
    "\n",
    "................................. falar do PCA \n",
    "\n",
    "Finalmente, surge a fase de aplicação dos algoritmos já mencionados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import sqlite3\n",
    "from sklearn import preprocessing\n",
    "import missingno as msno\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor # Nearest Neighbors Algorithm\n",
    "from sklearn.neural_network import MLPRegressor # Neural network Algorithm\n",
    "from sklearn import svm # Support Vector Machines Algorithm\n",
    "from sklearn import tree # Decision Trees Algorithm\n",
    "from statsmodels.graphics.correlation import plot_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"./database.sqlite\")\n",
    "display_graph = False\n",
    "\n",
    "def clean_data(data):\n",
    "    #this line displays the NaN distribution before data clean up\n",
    "    if display_graph:\n",
    "        msno.matrix(data)\n",
    "    data = data.replace(\"\", np.NaN)\n",
    "    data = data.dropna()\n",
    "    if display_graph:\n",
    "        msno.matrix(data)\n",
    "    return data\n",
    "\n",
    "def preprocess_data() :\n",
    "    matches = pd.read_sql_query('SELECT *, strftime(\"%Y\",date) as year, (B365H + BWH + IWH + LBH + WHH +  VCH )/6 AS home_odds, (B365D + BWD + IWD + LBD + WHD + VCD)/6 AS draw_odds,  (B365A + BWA + IWA + LBA + WHA + VCA )/6 AS away_odds FROM match',con)\n",
    "    matches = matches.iloc[:, np.r_[0,2,4,7,8,9,10, 55:77, 115:119 ]]\n",
    "\n",
    "    teams = pd.read_sql_query('SELECT team_api_id, (buildUpPlaySpeed + buildUpPlayDribbling + buildUpPlayPassing + defencePressure + defenceAggression + defenceTeamWidth)/6 as team_rating FROM team_attributes', con)\n",
    "    players = pd.read_sql_query('SELECT player_api_id, strftime(\"%Y\",date) as year, avg(potential) as player_potential, avg(overall_rating) as rating FROM player_attributes GROUP BY player_api_id, year', con)\n",
    "    \n",
    "    matches = clean_data(matches)\n",
    "    teams = clean_data(teams)\n",
    "    players = clean_data(players)\n",
    "      \n",
    "    result =pd.merge(matches, teams, left_on='home_team_api_id', right_on='team_api_id', how='left').drop('team_api_id', axis=1)\n",
    "    result =pd.merge(result, teams, left_on='away_team_api_id', right_on='team_api_id', how='left').drop('team_api_id', axis=1)\n",
    "    result.rename(columns={\"team_rating_x\": \"home_team_rating\", \"team_rating_y\": \"away_team_rating\"}, inplace=True)\n",
    "\n",
    "    for index in range(1,12):\n",
    "        player_home_id = \"home_player_\" + str(index)\n",
    "        player_away_id = \"away_player_\" + str(index)\n",
    "        result =pd.merge(result, players, left_on=[player_home_id, 'year'], right_on=['player_api_id', 'year'], how='left').drop(['player_api_id', player_home_id], axis=1)\n",
    "        result =pd.merge(result, players, left_on=[player_away_id, 'year'], right_on=['player_api_id', 'year'], how='left').drop(['player_api_id', player_away_id], axis=1)\n",
    "        result.rename(columns={\"player_potential_x\": player_home_id + \"_potential\", \"player_potential_y\": player_away_id + \"_potential\" , \"rating_x\": player_home_id + \"_rating\", \"rating_y\": player_away_id + \"_rating\"}, inplace=True)\n",
    "    \n",
    "    result = clean_data(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_call(X, Y, dataset): \n",
    "    pca = PCA(n_components=2)\n",
    "        \n",
    "    data_scaled = pd.DataFrame(preprocessing.scale(X),columns = X.columns) \n",
    "\n",
    "    principalComponents = pca.fit_transform(data_scaled)\n",
    "    \n",
    "   # print(pca.explained_variance_ratio_)\n",
    "   # print(pca.singular_values_)\n",
    "    \n",
    "   # print(principalComponents)\n",
    "   # principalDf = pd.DataFrame(data = principalComponents\n",
    "    #         , columns = ['principal component 1', 'principal component 2'])\n",
    "    \n",
    "    #finalDf = pd.concat([principalDf, Y], axis = 1)\n",
    "#    display(finalDf)\n",
    "\n",
    "    print (pd.DataFrame(pca.components_,columns=data_scaled.columns, index = ['PC-1','PC-2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X_train, Y_train, X_test, Y_test):\n",
    "    reg = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(r2_score(Y_test, y_pred))\n",
    "\n",
    "    \n",
    "    #plt.scatter(X_test, Y_test,  color='gray')\n",
    "    plt.plot(X_test, y_pred, color='red', linewidth=2)\n",
    "    plt.plot(X_test, Y_test, color='gray', linewidth=2)\n",
    "    plt.show()\n",
    "    \n",
    "    #print(reg.intercept_)\n",
    "    #print(reg.coef_)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbours\n",
    "\n",
    "Este algoritmo identifica quais os k vizinhos mais próximos, isto é, os k pontos do conjunto de treino que estão a uma menor distância do valor que está a ser previsto. A previsão irá corresponder à média ponderada entre esses k pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbour(X_train, X_test, Y_train, Y_test):\n",
    "    neighbour = KNeighborsRegressor(n_neighbors=2)\n",
    "    neighbour.fit(X_train, Y_train)\n",
    "\n",
    "    neighbour_pred = neighbour.predict(X_test)\n",
    "    \n",
    "    print(r2_score(Y_test, neighbour_pred))\n",
    "\n",
    "    \n",
    "    #plt.scatter(X_test, Y_test,  color='gray')\n",
    "    plt.plot(X_test, neighbour_pred, color='red', linewidth=2)\n",
    "    plt.plot(X_test, Y_test, color='gray', linewidth=2)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks\n",
    "\n",
    "As redes neuronais artificiais são inspiradas no funcionamento do cérebro humano. Estas redes são compostas por um elevado número de neurónios altamente ligados e a trabalhar em paralelo na resolução de problemas. Todo o seu conhecimento é adquirido através da aprendizagem e armazenado nas ligações. \n",
    "\n",
    "Nesta implementação é usado um Multi-Layer Perceptron. Neste tipo de modelos existe uma primeira layer (input layer), hidden layers (número variável) e uma última layer que corresponde à output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(X_train, X_test, Y_train, Y_test):\n",
    "    neural = MLPRegressor()\n",
    "    neural.fit(X_train, Y_train)\n",
    "\n",
    "    neural_pred = neural.predict(X_test)\n",
    "    print(r2_score(Y_test, neural_pred))\n",
    "\n",
    "    \n",
    "    #plt.scatter(X_test, Y_test,  color='gray')\n",
    "    plt.plot(X_test, neural_pred, color='red', linewidth=2)\n",
    "    plt.plot(X_test, Y_test, color='gray', linewidth=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines\n",
    "\n",
    "Este algoritmo procura identificar uma função f(X) que não se poderá desviar mais do que o valor de epsilon para cada valor de y presente no conjunto de treino. Simultaneamente, esta função deve tentar aproximar-se, o mais possível, de uma reta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machines(X_train, X_test, Y_train, Y_test):\n",
    "    #epsilon default value is 0.1\n",
    "    svm_instance = svm.SVR()\n",
    "    svm_instance.fit(X_train, Y_train)\n",
    "\n",
    "    svm_pred = svm_instance.predict(X_test)\n",
    "    print(r2_score(Y_test, svm_pred))\n",
    "\n",
    "    \n",
    "    #plt.scatter(X_test, Y_test,  color='gray')\n",
    "    plt.plot(X_test, svm_pred, color='red', linewidth=2)\n",
    "    plt.plot(X_test, Y_test, color='gray', linewidth=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees\n",
    "\n",
    "As árvores de decisão procuram ajustar-se a uma curva sinusoidal, com ligeiros desvios. Como resultado, são obtidas regressões lineares locais que aproximam essa curva.\n",
    "\n",
    "Para utilizar árvores de decisão em problemas de regressão, temos de definir uma métrica de impureza que se adeque a variáveis contínuas. Deste modo, deve ser definida como o erro quadrático médio dos nós.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_train, X_test, Y_train, Y_test):\n",
    "    dta = tree.DecisionTreeRegressor(criterion='mse')\n",
    "    dta.fit(X_train, Y_train)\n",
    "    \n",
    "    dta_pred = dta.predict(X_test)\n",
    "    print(r2_score(Y_test, dta_pred))\n",
    "\n",
    "   # plt.scatter(X_test, Y_test,  color='gray')\n",
    "    plt.plot(X_test, dta_pred, color='red', linewidth=2)\n",
    "    plt.plot(X_test, Y_test, color='gray', linewidth=2)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_info(team_id, year, dataset):\n",
    "    home_matches = dataset[dataset.home_team_api_id == team_id ] #('(home_team_api_id == @team_id) & (year == @year)')\n",
    "    away_matches = dataset[dataset.away_team_api_id == team_id ] #('(home_team_api_id == @team_id) & (year == @year)')\n",
    "    team_matches = away_matches.append(home_matches)\n",
    "    team_matches = team_matches[team_matches.year == year ]\n",
    "    return team_matches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     home_team_goal  away_team_goal  home_team_rating  away_team_rating\n",
      "88                1               1              51.0              52.0\n",
      "89                1               1              51.0              52.0\n",
      "90                1               1              51.0              52.0\n",
      "91                1               1              51.0              52.0\n",
      "140               3               1              51.0              52.0\n",
      "141               3               1              51.0              52.0\n",
      "142               3               1              49.0              52.0\n",
      "143               3               1              49.0              52.0\n",
      "155               1               0              47.0              52.0\n",
      "156               1               0              47.0              52.0\n",
      "157               1               0              47.0              52.0\n",
      "158               1               0              47.0              52.0\n",
      "175               3               2              54.0              52.0\n",
      "176               3               2              54.0              52.0\n",
      "177               3               2              52.0              52.0\n",
      "178               3               2              52.0              52.0\n",
      "191               2               1              49.0              52.0\n",
      "192               2               1              49.0              52.0\n",
      "193               2               1              49.0              52.0\n",
      "194               2               1              49.0              52.0\n",
      "404               1               1              52.0              52.0\n",
      "405               1               1              52.0              52.0\n",
      "406               1               1              52.0              52.0\n",
      "407               1               1              52.0              52.0\n",
      "4                 1               3              52.0              49.0\n",
      "5                 1               3              52.0              49.0\n",
      "6                 1               3              52.0              49.0\n",
      "7                 1               3              52.0              49.0\n",
      "57                1               3              52.0              51.0\n",
      "58                1               3              52.0              49.0\n",
      "59                1               3              52.0              51.0\n",
      "60                1               3              52.0              49.0\n",
      "120               2               1              52.0              49.0\n",
      "121               2               1              52.0              49.0\n",
      "147               1               3              52.0              54.0\n",
      "148               1               3              52.0              52.0\n",
      "149               1               3              52.0              54.0\n",
      "150               1               3              52.0              52.0\n",
      "207               2               0              52.0              52.0\n",
      "208               2               0              52.0              52.0\n",
      "209               2               0              52.0              52.0\n",
      "210               2               0              52.0              52.0\n",
      "322               2               2              52.0              47.0\n",
      "323               2               2              52.0              47.0\n",
      "324               2               2              52.0              47.0\n",
      "325               2               2              52.0              47.0\n",
      "362               2               3              52.0              49.0\n",
      "363               2               3              52.0              49.0\n",
      "364               2               3              52.0              49.0\n",
      "365               2               3              52.0              49.0\n",
      "412               1               0              52.0              46.0\n",
      "413               1               0              52.0              46.0\n",
      "414               1               0              52.0              46.0\n",
      "415               1               0              52.0              46.0\n",
      "      home_team_goal  away_team_goal  home_team_rating  away_team_rating\n",
      "PC-1        0.041250       -0.584993         -0.675219          0.447394\n",
      "PC-2        0.850006        0.189176          0.188802          0.453933\n"
     ]
    }
   ],
   "source": [
    "#def calculate_odds(match_id):\n",
    "#match = pd.read_sql_query('SELECT * FROM match WHERE id = {}'.format(1), con)\n",
    "dataset = preprocess_data()\n",
    "#print(dataset)\n",
    "\n",
    "team_dataset = get_team_info(9984, '2009', dataset)\n",
    "\n",
    "X = team_dataset.iloc[:, [5,6,11, 12]]\n",
    "print(X)\n",
    "X1 = preprocessing.scale(X)\n",
    "\n",
    "Y = team_dataset.iloc[:, 8]\n",
    "Y = preprocessing.scale(Y)\n",
    "\n",
    "dba = team_dataset.iloc[:, [5,6,8,9,10,11,12]]\n",
    "\n",
    "corr = dba[:-1].corr()\n",
    "\n",
    "#fig=plot_corr(corr,xnames=corr.columns)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X1,Y,test_size= 0.3)\n",
    "\n",
    "#linear_regression(X_train, Y_train, X_test, Y_test)\n",
    "PCA_call(X, Y, dataset)\n",
    "#k_nearest_neighbour(X_train, X_test, Y_train, Y_test)\n",
    "#neural_network(X_train, X_test, Y_train, Y_test)\n",
    "#support_vector_machines(X_train, X_test, Y_train, Y_test)\n",
    "#decision_tree(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Experimental evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
